#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
thann.py
--------
An advanced example of a Toroidal Hive (THANN) prototype with integrated dataset loading.
This version includes built-in support for selecting a dataset:
    - 'custom': Provide one or more image paths via command-line.
    - 'coco': Load images from a COCO sample folder.
    - 'shapenet': (Placeholder) For integrating 3D object datasets.
Additional processing (background removal, rendering, mesh extraction, texture baking)
remains unchanged.

Requirements:
    pip install torch transformers sentence-transformers rembg xatlas pillow numpy
"""

import argparse
import logging
import os
import time
import glob
import numpy as np
import rembg
import torch
import xatlas
from PIL import Image

from tsr.system import TSR
from tsr.utils import remove_background, resize_foreground, save_video
from tsr.bake_texture import bake_texture

##############################################################################
# Timer Utility
##############################################################################

class Timer:
    def __init__(self):
        self.items = {}
        self.time_scale = 1000.0  # ms
        self.time_unit = "ms"

    def start(self, name: str) -> None:
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        self.items[name] = time.time()
        logging.info(f"{name} ...")

    def end(self, name: str) -> float:
        if name not in self.items:
            return
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        start_time = self.items.pop(name)
        delta = time.time() - start_time
        t = delta * self.time_scale
        logging.info(f"{name} finished in {t:.2f}{self.time_unit}.")
        return t

timer = Timer()

##############################################################################
# Logging Configuration
##############################################################################

logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s", level=logging.INFO
)

##############################################################################
# Dataset Loader Functions
##############################################################################

def load_custom_images(image_paths):
    """Load images from a list of provided file paths."""
    images = []
    for image_path in image_paths:
        image = np.array(Image.open(image_path).convert("RGB"))
        images.append(image)
    return images

def load_coco_dataset(dataset_dir):
    """
    Load images from a sample COCO dataset directory.
    This function assumes that dataset_dir contains JPEG/PNG images.
    """
    image_files = glob.glob(os.path.join(dataset_dir, "*.jpg")) + glob.glob(os.path.join(dataset_dir, "*.png"))
    if len(image_files) == 0:
        logging.error(f"No images found in {dataset_dir}")
    images = []
    for file in image_files:
        image = np.array(Image.open(file).convert("RGB"))
        images.append(image)
    logging.info(f"Loaded {len(images)} images from COCO dataset at {dataset_dir}.")
    return images

def load_shapenet_dataset(dataset_dir):
    """
    (Placeholder) Load images or 3D models from a ShapeNet dataset directory.
    In a full implementation, you would parse ShapeNet 3D models and/or their rendered views.
    Here, we load sample rendered images for demonstration.
    """
    image_files = glob.glob(os.path.join(dataset_dir, "*.jpg")) + glob.glob(os.path.join(dataset_dir, "*.png"))
    if len(image_files) == 0:
        logging.error(f"No images found in {dataset_dir}")
    images = []
    for file in image_files:
        image = np.array(Image.open(file).convert("RGB"))
        images.append(image)
    logging.info(f"Loaded {len(images)} sample rendered images from ShapeNet dataset at {dataset_dir}.")
    return images

##############################################################################
# Argument Parsing
##############################################################################

parser = argparse.ArgumentParser()
parser.add_argument("image", type=str, nargs="*", help="Path to input image(s). Ignored if --dataset is specified.")
parser.add_argument(
    "--dataset",
    type=str,
    default="custom",
    choices=["custom", "coco", "shapenet"],
    help="Choose dataset mode: 'custom' for manual image paths; 'coco' or 'shapenet' for built-in dataset loading. Default: custom",
)
parser.add_argument(
    "--dataset-dir",
    type=str,
    default="",
    help="Directory of the dataset to load if --dataset is not 'custom'.",
)
parser.add_argument(
    "--device",
    default="cuda:0",
    type=str,
    help="Device to use. If no CUDA-compatible device is found, will fallback to 'cpu'. Default: 'cuda:0'",
)
parser.add_argument(
    "--pretrained-model-name-or-path",
    default="stabilityai/TripoSR",
    type=str,
    help="Path to the pretrained model. Could be a Hugging Face model id or a local path. Default: 'stabilityai/TripoSR'",
)
parser.add_argument(
    "--chunk-size",
    default=8192,
    type=int,
    help="Evaluation chunk size for surface extraction and rendering. Smaller chunk size reduces VRAM usage but increases computation time. Default: 8192",
)
parser.add_argument(
    "--mc-resolution",
    default=256,
    type=int,
    help="Marching cubes grid resolution. Default: 256"
)
parser.add_argument(
    "--no-remove-bg",
    action="store_true",
    help="If specified, the background will NOT be automatically removed from the input image, and the input image should be an RGB image with grey background and properly-sized foreground. Default: false",
)
parser.add_argument(
    "--foreground-ratio",
    default=0.85,
    type=float,
    help="Ratio of the foreground size to the image size. Only used when --no-remove-bg is not specified. Default: 0.85",
)
parser.add_argument(
    "--output-dir",
    default="output/",
    type=str,
    help="Output directory to save the results. Default: 'output/'",
)
parser.add_argument(
    "--model-save-format",
    default="obj",
    type=str,
    choices=["obj", "glb"],
    help="Format to save the extracted mesh. Default: 'obj'",
)
parser.add_argument(
    "--bake-texture",
    action="store_true",
    help="Bake a texture atlas for the extracted mesh, instead of vertex colors",
)
parser.add_argument(
    "--texture-resolution",
    default=2048,
    type=int,
    help="Texture atlas resolution, only useful with --bake-texture. Default: 2048"
)
parser.add_argument(
    "--render",
    action="store_true",
    help="If specified, save a NeRF-rendered video. Default: false",
)
args = parser.parse_args()

output_dir = args.output_dir
os.makedirs(output_dir, exist_ok=True)

device = args.device
if not torch.cuda.is_available():
    device = "cpu"

##############################################################################
# Model Initialization
##############################################################################

timer.start("Initializing model")
model = TSR.from_pretrained(
    args.pretrained_model_name_or_path,
    config_name="config.yaml",
    weight_name="model.ckpt",
)
model.renderer.set_chunk_size(args.chunk_size)
model.to(device)
timer.end("Initializing model")

##############################################################################
# Image / Dataset Processing
##############################################################################

timer.start("Processing images")
if args.dataset == "custom":
    if len(args.image) == 0:
        logging.error("No image paths provided and dataset mode is 'custom'. Exiting.")
        exit(1)
    images = load_custom_images(args.image)
elif args.dataset == "coco":
    if args.dataset_dir == "":
        logging.error("Please provide --dataset-dir for the COCO dataset.")
        exit(1)
    images = load_coco_dataset(args.dataset_dir)
elif args.dataset == "shapenet":
    if args.dataset_dir == "":
        logging.error("Please provide --dataset-dir for the ShapeNet dataset.")
        exit(1)
    images = load_shapenet_dataset(args.dataset_dir)
else:
    images = []

# If background removal is enabled, process the images accordingly
processed_images = []
if not args.no_remove_bg:
    rembg_session = rembg.new_session()
    for i, image in enumerate(images):
        image = remove_background(Image.fromarray(image), rembg_session)
        image = resize_foreground(image, args.foreground_ratio)
        image = np.array(image).astype(np.float32) / 255.0
        image = image[:, :, :3] * image[:, :, 3:4] + (1 - image[:, :, 3:4]) * 0.5
        image = Image.fromarray((image * 255.0).astype(np.uint8))
        # Save processed image to output directory
        image_output_dir = os.path.join(output_dir, str(i))
        os.makedirs(image_output_dir, exist_ok=True)
        image.save(os.path.join(image_output_dir, f"input.png"))
        processed_images.append(image)
else:
    # If no background removal, assume images are ready to be used
    processed_images = [Image.fromarray(image) for image in images]
timer.end("Processing images")

##############################################################################
# Model Inference, Rendering, Mesh Extraction & Export
##############################################################################

for i, image in enumerate(processed_images):
    logging.info(f"Running image {i + 1}/{len(processed_images)} ...")

    timer.start("Running model")
    with torch.no_grad():
        scene_codes = model([image], device=device)
    timer.end("Running model")

    if args.render:
        timer.start("Rendering")
        render_images = model.render(scene_codes, n_views=30, return_type="pil")
        for ri, render_image in enumerate(render_images[0]):
            render_image.save(os.path.join(output_dir, str(i), f"render_{ri:03d}.png"))
        save_video(render_images[0], os.path.join(output_dir, str(i), f"render.mp4"), fps=30)
        timer.end("Rendering")

    timer.start("Extracting mesh")
    meshes = model.extract_mesh(scene_codes, not args.bake_texture, resolution=args.mc_resolution)
    timer.end("Extracting mesh")

    out_mesh_path = os.path.join(output_dir, str(i), f"mesh.{args.model_save_format}")
    if args.bake_texture:
        out_texture_path = os.path.join(output_dir, str(i), "texture.png")

        timer.start("Baking texture")
        bake_output = bake_texture(meshes[0], model, scene_codes[0], args.texture_resolution)
        timer.end("Baking texture")

        timer.start("Exporting mesh and texture")
        xatlas.export(out_mesh_path,
                      meshes[0].vertices[bake_output["vmapping"]],
                      bake_output["indices"],
                      bake_output["uvs"],
                      meshes[0].vertex_normals[bake_output["vmapping"]])
        Image.fromarray((bake_output["colors"] * 255.0).astype(np.uint8))\
             .transpose(Image.FLIP_TOP_BOTTOM)\
             .save(out_texture_path)
        timer.end("Exporting mesh and texture")
    else:
        timer.start("Exporting mesh")
        meshes[0].export(out_mesh_path)
        timer.end("Exporting mesh")
